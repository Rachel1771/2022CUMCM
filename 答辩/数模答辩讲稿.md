# 数模答辩讲稿

### **自我介绍**

尊敬的评委老师们，你们好，我是来自**大学20级的学生队员C，在我右手边的是同为20级的队员B，左手边的是队员A。我们所选题目是C题，在比赛过程中，我主要负责第一问的建模以及论文的撰写，队员A同学负责二三的建模求解，队员B同学负责第四问的求解和数据处理，三人共同参与了论文的修改和整理。下面由我来陈述我们对该题的求解流程。



### **首先是数据处理**

观察数据发现缺失值较多，题目解释为未检测到该成分。我们综合考虑到机器采样和人工手法不同所带来的误差，认为未检测到但不代表没有。总体数据的主要特点就是成分性，成分定和理论应为100%。据此我们进行了数据缺失的填补，首先对数据归一化处理，后用随机森林算法进行训练预测，填补**表二**空白，结合**参考文献**查询文物的一般测量误差率，进一步缩小填补后的误差，保证数据足够的可信度，根据所给的标准再剔除无效数据。

### **针对问题一**

##### **1.1第一小问**

首先对表单一进行了正态检验，后续采用卡方检验分析其数据之间的显著性。以及斯皮尔曼相关系数分析法分析了其数据之间的相关性，发现风化和类型存在显著性、风化与纹饰和类型正相关、和颜色成负相关；

##### **1.2第二小文**

为探究化学成分的统计规律，通过数据诊断发现数据有强多重共线性的情况下，采用了基于最小二乘法改良的岭回归模型，该模型能够有效的解决数据之间的强共线性。通过模型建立后进行拟合求解出化学成分之间的函数关系式，通过函数式就能进行预测，通过预测得出的结果大部分成分和为100%，效果较好。

### 针对问题二

 本问是对数据的规律性和划分做分析处理。基于第一小问，依据高钾铅钡的风化和未风化划分，利用熵权法求解各自化学成分的信息熵，通过信息熵其值来判断其大概的分类规律。同时我们引入生物类别划分之间的"亚种"这一概念来解释本问中所提的亚类。我们认为不同玻璃类型之间的无风化的样品会存在不同的亚类，亚类划分向风化靠拢，因为随着时间推移最终风化是必然性，划分的刻度就是趋向于风化的程度。

为了得到更稳定的分类器，我们在本问提出K-means++—BP神经网络混合模型来进行亚类划分。首先使用肘部法与轮廓法确定聚类簇K，然后使用K-means++进行无监督聚类，将聚类后的结果过采样处理作为数据集，使用BP神经网络进行训练分类，结合遗传算法启发调优得到分类模型。 使用五折交叉验证进行验证，指标几乎都达到百分百。通过计算一阶灵敏度，二阶灵敏度，总阶敏感度对BP神经网络进行敏感度分析，所有二阶灵敏度指数的值都小于0.015，模型敏感度低。

### 针对问题三

问题三就是根据化学成分对所属类别进行分类的问题。我们提出集成学习思想进行分类预测。

首先结合表单二用随机森林对表单三进行数据填补，其次使用多种集成思想：软投票，Stacking，Bagging进行模型集成，通过网格搜索进行参数寻优。然后划分表单二的数据为训练集以及测试集进行模型训练和验证，通过验证发现模型表现良好，指标几乎都达到百分百。最后我们使用表单二的数据作为训练集进行训练，并对表单三进行预测。我们通过计算敏感度SE，特异性SP，一阶灵敏度，二阶灵敏度，总阶敏感度进行敏感度分析，得到敏感度SE，特异性SP都为1，所有二阶灵敏度指数的值都小于0.045，模型敏感度低的结果。



### 针对问题四

第四问提出对不同类别的样品进行关联性分析和不同类别之间的差异性分析。

对于关联性分析，因为数据的样本数量较少且需要进行类别分组，故采用了灰色关联分析的方法对各类别样品的成分之间进行关系分析；

对于差异性问题，我们采用了多配对样本的Friedman检验对已完成分类的样品进行成分差异研究，由于Friedman检验是总体上的差异性研究，故我们补充了Nemenyi事后检验的方法对两两成分之间的差异性也进行了比较研究，并得到论文所给的结果。

我的陈述到此结束，谢谢大家 。





##  **数据处理**

1. 数据填补

2. 随机森林填补



### **为什么进行填补**

   1. 题目所给空白是未检测到但不代表没有，存在的机器的测量误差和一些其他的因素导致检测不到。

   2.故采用随机森林进行预测填补，尽量减少前述误差带来的不准确性



### **为什么使用随机森林填补**

   1. 对比其他的填补方式（拉格兰日插值），MSE指标好

   2. 分析

- **优点**

​        1. 随机森林填补通过构造多棵决策树对缺失值进行填补，使得填补得到的数据具有随机性和不确定性，更能反映出这些未知数据的真实分布；

​        2. 随机森林填补由于在构造决策树过程中，每个分支节点选用随机的部分特征而不是全部特征，所以能很好的应用到高维数据的填补；

​        3. 随机森林算法本身就具有很好的分类精度，从而也更进一步确保了得到的填补值的准确性和可靠性。

- **缺点：**

​        1. 解释性比较差



### **填补产生的问题**

1. 导致成分和超出100%，然后根据权重进行限定
2. 剔除无效数据
3. 根据采样点类型，修改表面风化分类



##  **第一问**

1. 岭回归解决共线性



##  **第二问**

K-means++ && BP

1. K-means++ 聚类

2. （提不用主成分分析）

3. 存在随机性（聚类结果存在随机性）

1. 选择聚类结果好的结果作为数据集，使用BP进行训练



### **为什么不用主成分分析**

#### 我们使用主成分分析之后，通过肘部法以及轮廓法，发现最合适聚类簇数等于所取的最重要成分数。



###  **敏感度**

S1：度量单变量输入对输出方差的影响贡献度。

S2：度量两个变量输入相互作用对输出方差的贡献。

ST ：度量模型输入对输出方差的贡献，在一阶，二阶乃至更高阶都有计算



1. 使用交叉验证，发现指标高。

2. 测试集上的指标都为1

3. 二阶交互作用小，指标都小于0.015



### **如何评价分类结果**

D:\workspace\CUMCM2022\CUMCM2022支撑材料\excel\result\2\k-means高钾.xlsx



具体可以从氧化钾(K2O)的排序看出来

我们是借鉴生物类别的亚种划分进行，生物类别的亚种划分是指一个物种A和物种B他们有着明显的生殖隔离（马和驴，狼和狗），其中B是由A的部分种群迁移到一个新的环境中，受环境影响演变成而来的。

我们认为，一种玻璃品种的主要成分相差无几，所以成分的变化是风化导致的，故此我们认为根据化学成分聚类出的结果是在风化程度上的划分，根据风化程度进而演变的类别。



![img](https://docimg5.docs.qq.com/image/AgAABWcWUk3_oO03SHRCqKZfi4syAFwE.png?w=1397&h=769)



### **SPSSPRO演示**

![img](https://docimg8.docs.qq.com/image/AgAABWcWUk0WGRNLTHhJbpzOltcWdcrb.png?w=961&h=259)



高钾：

![img](https://docimg1.docs.qq.com/image/AgAABWcWUk2CZhNcS9tCvJGvzAXrvY3V.png?w=994&h=685)

![img](https://docimg1.docs.qq.com/image/AgAABWcWUk1qGJocbnpC8YMtLreZ5ftr.png?w=784&h=560)



##  **第三问**

模型集成

1. 使用软投票，Stacking，Bagging
2. 群策群议，泛化性强



### **选取的模型**

**随机森林（剪枝，增加泛化性）**

1. bootstrap：对样本集进行有放回抽样来构建树

2. min_samples_leaf:1   叶子节点含有的最少样本。若叶子节点样本数小于min_samples_leaf，则对该叶子节点和兄弟叶子节点进行剪枝，只留下该叶子节点的父节点。整数型表示个数，浮点型表示取大于等于（样本数 * min_samples_leaf)的最小整数。

3. min_weight_fraction_leaf：0叶子节点最小的样本权重和。叶子节点如果小于这个值，则会和兄弟节点一起被剪枝，只保留叶子节点的父节点。默认是0，则不考虑样本权重问题。一般来说，如果有较多样本的缺失值或偏差很大，则尝试设置该参数值。



**LogisticRegression**

有线性边界的分类问题有很好的预测效果，对于非线性的边界是无能为力的

L2 正则化



**SVC支持向量机**

通过计算决策分界线到样本的距离来确定分界线。



**StackingCVClassifier**

分类器：Ada, GBDT, LogisticRegression,Randomforest

元分类器：SVC

设置五折交叉验证



**GradientBoostingClassifier**

Gradient就是去拟合Loss function的梯度，将其作为新的弱回归树加入到总的算法中即可。

GB以正向阶段方式建立了一个加性模型；它允许优化任意可微损失函数。在每个阶段``n_classes_``回归树拟合在二项或多项偏差损失函数的负梯度上。二进制分类是一种特殊的情况，其中只诱导了一棵回归树。

损失函数的大小可以用来描述模型的“靠谱”程度。如果我们的模型能够让损失函数持续的下降，则说明模型在不停的改进，而最好的方式就是让损失函数在其梯度方向上下降。Gradient Boosting 在迭代的时候选择梯度下降的方向来保证最后的结果最好。



**AdaBoostClassifier**

AdaBoost首先使用一个分类器对原始数据集进行拟合分类，然后对分类不正确的实例进行调整，将调整后的数据集用于后续的分类器，让分类器关注困难样本。	



**LGBMClassifier**

比较适合大的数据集，而对于较小的数据集(<10000条记录)，lightGBM可能不是最佳选择。所以，如果进行调优lightgbm参数，这可能没有帮助。



对于LogisticRegression,SVC设置小的误分类惩罚，误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。



###  **敏感性分析**

S1：度量单变量输入对输出方差的影响贡献度。

S2：度量两个变量输入相互作用对输出方差的贡献。

ST ：度量模型输入对输出方差的贡献，在一阶，二阶乃至更高阶都有计算

（负数的情况，是由于样本数量较少，存在抽样误差，导致指标为负数。）

1. 测试集上的指标都为1
2. 敏感度指标（SE，漏检）为1
3. 特异性（SP，误判）为1

3. 二阶敏感度都小于0.045



##  **数据量导致机器学习算法适用性差**



1. 使用多个不同的模型进行集成（lightGBM适合较大数据集的样本，LogisticRegression有线性边界）：群策群议，防止过拟合（数据集少）

2. 模型选的好：随机森林相比于决策树更不容易过拟合。使用多样性模型，提高集成的效果

3. 剪枝，提高泛化性

4. 使用K-fold，从评价指标上讲：效果好（第二问）

5. 进行样本均衡处理（第二问）

6. 使用L2正则化：LogisticRegression

7. 调小惩罚项：对于LogisticRegression,SVC设置小的误分类惩罚，误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。



##  **创新点**

1. 补成100%（数据填补的方式合理）

2. 根据采样点的类型修改标签

3. 第一问解决共线性问题，拟合效果好

4. 第二问使用BP训练，得到稳定的分类器

5. 第三问联合表二表三进行数据填补，使用多模型集成，在预测的时候使用所有的数据进行训练，预测的置信度高

6. 第四问



## **三个人分工**

我们我们三人都有主要的分工，

队员A主要负责二，三问的求解以及代码的编写，使用excel或者Python进行部分数据处理，通过python计算第一问以及第四问的回归方程。

队员B进行第一问以及第四问的求解，以及使用excel对数据进行处理。

队员C参与所有问题求解过程的讨论，主要进行论文的编写，队员A与队员B都参与论文的部分编写的工作。

流程图等是由队员A以及队员B绘制的。



## **引用**

### **3**

集成学习方法是一项强大的技术，它通过组合多个模型的输出来生成最终预测



![img](https://docimg2.docs.qq.com/image/AgAABWcWUk3Sba8Yz21GNa0uFvwa1TXV.png?w=863&h=645)



### **4**

选择并使用一组准确且多样化的集成成员时，可以提高最终集成性能与泛化能力,

![img](https://docimg3.docs.qq.com/image/AgAABWcWUk3fSQeKGRBExLXWOfgNo0uE.png?w=734&h=659)

### **8**

![img](https://docimg7.docs.qq.com/image/AgAABWcWUk0pC0CZgAtCoZN56e4lVXex.png?w=993&h=442)



**惩罚项**”是正则化的常用方式，为了防止系数过大从而让模型变得复杂。



## **注意点**

1. 记下评委的问题
